---
title: "“Our app doesn’t have AI” is the new differentiator now"
date: '2024-06-12T20:17:33+05:30'
status: publish

author: Bhagyesh Pathak
excerpt: ''
type: post
id: 2208
category:
- Uncategorized
tag: []
layout: post
---

I love LLMs (Large Language Models) tools aka AI tools, they’ve changed the way I work, what I work and how I envisage my future. If you’ve been using it, you know what I mean.

And so, it is natural for companies to ride the AI wave.  
“We are the first AI code companion company.”  
“We are the first AI 3D modelling company.”  
“We are the first AI translation company.”  
“We are the first AI architecture company.”  
“We are the first AI education company.”  
“We are the first AI medical diagnostic company.”

Add to it Microsoft and Apple’s support for local data-trained AI:  
Recall feature\[1\] and Apple Intelligence.\[2\]

If you remember, most startups used to bring in such AI-related solutions for people. At a smaller scale. And people thought they were experiments. Most of the 700 lb gorillas facilitated the technology, but they didn’t make system-wide changes that much. OS-wide I mean.

For example, if you use a Windows PC like me, you’d find that Microsoft secretly installed Co-pilot on the PCs. Even a tech-savvy person like me didn’t realize when and how they did it. Thank god, I turned it off as soon as I found it.

There’s already an ongoing raging public discussion (Not on LinkedIn. LinkedIn is docile. It is still living in DEI, ESG era) regarding the force-feeding of these AI integrations. And most of them bear merit.

After yesterday’s Apple unveiling of Apple Intelligence, it was clear that companies are coming after users’ data. And there are some fanatics who are trying to rationalize that the data is safe, there is no surveillance. I think Apple’s carefully nurtured brand image of “safety” has a lot to do with these fanatics being unable to see what a deal they’re making with the devil. Talking of Apple’s ethical track record, it is as bad as any other gorilla’s. Remember the recent €2 b EU fine?\[3\]

“But the data is processed locally!” Hahaha, that’s the thing. This reminds me of Wittgenstein’s Ruler, which briefly states that “unless you have confidence in the ruler’s reliability, if you use a ruler to measure a table you may also be using the table to measure the ruler.”\[4\]

In this case, our fanatic’s proclamation that “it is processed locally” assumes the reliability of his understanding of local processing mechanisms. If they are flawed, then shouting “local processing” is meaningless. And if you have shown any interest in how AI works, you’d know that you can’t understand it really. No matter how smart you’re. Because the AI neural models are black boxes.

So, whom do we trust?  
The experts?  
But we don’t have a scale to weigh who is a “true” expert.

You know what, the larger question is, do you NEED Microsoft or Apple going through your private data—whole PC and cell phone—24/7/365 to provide you with some insight and files that you thought you had misplaced?

I don’t know about you, but I don’t NEED that.  
I don’t need to accept surveillance, a house arrest for no crimes that I committed.

Before the year 2023, “our app has AI” was a product differentiator.  
Not anymore.

Foot notes:  
\[1\] In this video, Microsoft CEO Satya Nadella talks about Recall feature in windows. It has been rolledback after severe backlash, but enjoy this 1 minute clip:   
\[2\] The Apple Intelligence demo in 5 minutes: [https://www.youtube.com/watch?v=Q\_EYoV1kZWk](https://www.youtube.com/watch?v=Q_EYoV1kZWk)  
\[3\] EU hits Apple with €1.8B antitrust fine for abusive app terms:   
\[4\] Wittgenstein’s Ruler: How to Not Be Fooled by Authority: